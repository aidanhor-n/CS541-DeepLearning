{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739795c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from flowability_data_upload.Research.main import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7703077",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399e86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "def load_data():\n",
    "    x = Data()\n",
    "    x.importnewpowders()\n",
    "    df_data = pd.DataFrame(x.data)\n",
    "    df_flow = pd.DataFrame(x.flow)\n",
    "    df_noflow = pd.DataFrame(x.noflow)\n",
    "\n",
    "    return df_data, df_flow, df_noflow\n",
    "\n",
    "df_data, df_flow, df_noflow = load_data()\n",
    "\n",
    "df_all = df_data.copy()\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c085716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MW_I_718_0-10.txt', 'S1VRC0706-5_Excel.txt',\n",
       "       'HCS_C103H_+10,-45.txt', 'S1VRC0706-4_Excel.txt',\n",
       "       'AEE_WP-301_1-5_AA_3-7.txt', 'HCS_C103N2_+10,-45.txt',\n",
       "       'HCS_C103N1_+10,-45.txt', 'S1VRC0706-6_Excel.txt',\n",
       "       'Valimet_6061_SPE.txt'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noflow['Powder'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e340b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noflow = df_noflow.reset_index(drop = True)\n",
    "\n",
    "train_noflow_powders = ['MW_I_718_0-10.txt', 'S1VRC0706-5_Excel.txt',\n",
    "       'HCS_C103H_+10,-45.txt', 'S1VRC0706-4_Excel.txt',\n",
    "       'AEE_WP-301_1-5_AA_3-7.txt']\n",
    "test_noflow_powders = ['HCS_C103N2_+10,-45.txt',\n",
    "       'HCS_C103N1_+10,-45.txt', 'S1VRC0706-6_Excel.txt',\n",
    "       'Valimet_6061_SPE.txt']\n",
    "\n",
    "train_df_noflow = df_noflow.drop(df_noflow[df_noflow['Powder'].isin(test_noflow_powders)].index)\n",
    "test_df_noflow = df_noflow.drop(df_noflow[df_noflow['Powder'].isin(train_noflow_powders)].index)\n",
    "\n",
    "train_powder_noflow = train_df_noflow.pop(\"Powder\")\n",
    "train_df_noflow.pop(\"Flow\")\n",
    "train_target_noflow = train_df_noflow.pop(\"Flow Class\")\n",
    "\n",
    "test_powder_noflow = test_df_noflow.pop(\"Powder\")\n",
    "test_df_noflow.pop(\"Flow\")\n",
    "test_target_noflow = test_df_noflow.pop(\"Flow Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaaf70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "noflow_scaler = StandardScaler()\n",
    "\n",
    "X_valid_noflow = train_df_noflow.sample(int(len(train_df_noflow) * 0.2))\n",
    "X_train_noflow = train_df_noflow.drop(X_valid_noflow.index)\n",
    "\n",
    "X_train_noflow = noflow_scaler.fit_transform(X_train_noflow)\n",
    "X_valid_noflow = noflow_scaler.transform(X_valid_noflow)\n",
    "X_test_noflow = noflow_scaler.transform(test_df_noflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2632e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S1VRC0706-3_Excel.txt', 'WIP-C1.txt', 'WIP-W1.txt',\n",
       "       'MW_Ti-Nb-Zr_0-63.txt', 'WIP-W2.txt', 'MW_Ti-Nb-Zr_64-150.txt',\n",
       "       'V5_Al-P1015_99.8%-Al.txt', 'MW_Ti-Nb_64-150.txt',\n",
       "       'S1VRC0706-2_Excel.txt', 'MW_SS-17-4_64-150.txt',\n",
       "       'Lincoln_SHS_7574HV.txt', 'Lincoln_SHS_9172HV.txt',\n",
       "       'Al-Cr_75-Percent_6061_1.1.txt', 'MW_SS-17-4_10-45.txt',\n",
       "       'MW_Ti-Nb_0-63.txt', 'S1VRC0706-1_Excel.txt',\n",
       "       'Lincoln_SHS_8000HV.txt', 'V_AA-4047.txt', 'V_AA-2024.txt',\n",
       "       'WIP-BC1.txt', 'HCS_TaH_-230+PAN.txt', 'V_Al-P1015_99.8%-Al.txt',\n",
       "       'V6_Al-P1015_99.8%-Al.txt', 'MW_FeMnAl-C_0-45.txt'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow['Powder'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be25bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow = df_flow.reset_index(drop = True)\n",
    "\n",
    "train_flow_powders = ['S1VRC0706-3_Excel.txt', 'WIP-C1.txt', 'WIP-W1.txt',\n",
    "       'MW_Ti-Nb-Zr_0-63.txt', 'WIP-W2.txt', 'MW_Ti-Nb-Zr_64-150.txt',\n",
    "       'V5_Al-P1015_99.8%-Al.txt', 'MW_Ti-Nb_64-150.txt',\n",
    "       'S1VRC0706-2_Excel.txt', 'MW_SS-17-4_64-150.txt',\n",
    "       'Lincoln_SHS_7574HV.txt', 'Lincoln_SHS_9172HV.txt',\n",
    "       'Al-Cr_75-Percent_6061_1.1.txt', \n",
    "       'MW_Ti-Nb_0-63.txt', 'S1VRC0706-1_Excel.txt',\n",
    "       'Lincoln_SHS_8000HV.txt', 'V_AA-4047.txt', 'V_AA-2024.txt', 'V6_Al-P1015_99.8%-Al.txt']\n",
    "test_flow_powders = ['WIP-BC1.txt', 'HCS_TaH_-230+PAN.txt', 'V_Al-P1015_99.8%-Al.txt',\n",
    "       'MW_SS-17-4_10-45.txt', 'MW_FeMnAl-C_0-45.txt']\n",
    "\n",
    "train_df_flow = df_flow.drop(df_flow[df_flow['Powder'].isin(test_flow_powders)].index)\n",
    "test_df_flow = df_flow.drop(df_flow[df_flow['Powder'].isin(train_flow_powders)].index)\n",
    "\n",
    "train_powder_flow = train_df_flow.pop(\"Powder\")\n",
    "train_flow = train_df_flow.pop(\"Flow\")\n",
    "train_target_flow = train_df_flow.pop(\"Flow Class\")\n",
    "\n",
    "test_powder_flow = test_df_flow.pop(\"Powder\")\n",
    "test_flow = test_df_flow.pop(\"Flow\")\n",
    "test_target_flow = test_df_flow.pop(\"Flow Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "685111e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "flow_scaler = StandardScaler()\n",
    "\n",
    "X_valid_flow = train_df_flow.sample(int(len(train_df_flow) * 0.2))\n",
    "X_train_flow = train_df_flow.drop(X_valid_flow.index)\n",
    "\n",
    "X_train_flow = flow_scaler.fit_transform(X_train_flow)\n",
    "X_valid_flow = flow_scaler.transform(X_valid_flow)\n",
    "X_test_flow = flow_scaler.transform(test_df_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7498a4",
   "metadata": {},
   "source": [
    "# Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df80792",
   "metadata": {},
   "source": [
    "## Flow AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84801d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 18:56:33.987930: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# data dimensions // hyperparameters \n",
    "input_dim = X_train_flow.shape[1]\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "\n",
    "# https://keras.io/layers/core/\n",
    "flow_autoencoder = tf.keras.models.Sequential([\n",
    "    \n",
    "    # deconstruct / encode\n",
    "    tf.keras.layers.Dense(input_dim, activation='elu', input_shape=(input_dim, )), \n",
    "    tf.keras.layers.Dense(16, activation='elu'),\n",
    "    tf.keras.layers.Dense(8, activation='elu'),\n",
    "    tf.keras.layers.Dense(4, activation='elu'),\n",
    "    tf.keras.layers.Dense(3, activation='elu'),\n",
    "    \n",
    "    # reconstruction / decode\n",
    "    tf.keras.layers.Dense(4, activation='elu'),\n",
    "    tf.keras.layers.Dense(8, activation='elu'),\n",
    "    tf.keras.layers.Dense(16, activation='elu'),\n",
    "    tf.keras.layers.Dense(input_dim, activation='elu')\n",
    "    \n",
    "])\n",
    "\n",
    "# https://keras.io/api/models/model_training_apis/\n",
    "flow_autoencoder.compile(optimizer=\"adam\", \n",
    "                    loss=\"mse\",\n",
    "                    metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33667044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "yyyymmddHHMM = datetime.now().strftime('%Y%m%d%H%M')\n",
    "\n",
    "# new folder for a new run\n",
    "log_subdir = f'{yyyymmddHHMM}_batch{BATCH_SIZE}_layers{len(flow_autoencoder.layers)}'\n",
    "\n",
    "# define our early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=10,\n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='autoencoder_best_weights.hdf5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    f'logs/{log_subdir}',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    update_freq='batch'\n",
    ")\n",
    "\n",
    "# callbacks argument only takes a list\n",
    "cb = [early_stop, save_model, tensorboard]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be8dd1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.4268 - acc: 0.2626 - val_loss: 0.2065 - val_acc: 0.3652\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1743 - acc: 0.4602 - val_loss: 0.1479 - val_acc: 0.5040\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1418 - acc: 0.5164 - val_loss: 0.1320 - val_acc: 0.5455\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1257 - acc: 0.5618 - val_loss: 0.1158 - val_acc: 0.5852\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1118 - acc: 0.5899 - val_loss: 0.1089 - val_acc: 0.5895\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1070 - acc: 0.5917 - val_loss: 0.1060 - val_acc: 0.5880\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1049 - acc: 0.5934 - val_loss: 0.1045 - val_acc: 0.5972\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1033 - acc: 0.5935 - val_loss: 0.1030 - val_acc: 0.5991\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1022 - acc: 0.5935 - val_loss: 0.1026 - val_acc: 0.5847\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.1013 - acc: 0.5934 - val_loss: 0.1010 - val_acc: 0.5960\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.1003 - acc: 0.5945 - val_loss: 0.1004 - val_acc: 0.5969\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0992 - acc: 0.5975 - val_loss: 0.0991 - val_acc: 0.6011\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0982 - acc: 0.5989 - val_loss: 0.0983 - val_acc: 0.6037\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0972 - acc: 0.6001 - val_loss: 0.0970 - val_acc: 0.6066\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0961 - acc: 0.6015 - val_loss: 0.0964 - val_acc: 0.6102\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0953 - acc: 0.6045 - val_loss: 0.0957 - val_acc: 0.6054\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0944 - acc: 0.6088 - val_loss: 0.0953 - val_acc: 0.6122\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0939 - acc: 0.6141 - val_loss: 0.0945 - val_acc: 0.6249\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0934 - acc: 0.6176 - val_loss: 0.0944 - val_acc: 0.6238\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0929 - acc: 0.6204 - val_loss: 0.0932 - val_acc: 0.6241\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0926 - acc: 0.6214 - val_loss: 0.0930 - val_acc: 0.6304\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0923 - acc: 0.6246 - val_loss: 0.0933 - val_acc: 0.6312\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0920 - acc: 0.6265 - val_loss: 0.0925 - val_acc: 0.6343\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0916 - acc: 0.6272 - val_loss: 0.0921 - val_acc: 0.6320\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0914 - acc: 0.6278 - val_loss: 0.0922 - val_acc: 0.6334\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0912 - acc: 0.6281 - val_loss: 0.0922 - val_acc: 0.6307\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0910 - acc: 0.6296 - val_loss: 0.0924 - val_acc: 0.6352\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0908 - acc: 0.6290 - val_loss: 0.0914 - val_acc: 0.6320\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0906 - acc: 0.6316 - val_loss: 0.0919 - val_acc: 0.6363\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0905 - acc: 0.6322 - val_loss: 0.0923 - val_acc: 0.6368\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0903 - acc: 0.6312 - val_loss: 0.0914 - val_acc: 0.6395\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0902 - acc: 0.6320 - val_loss: 0.0909 - val_acc: 0.6398\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0899 - acc: 0.6320 - val_loss: 0.0919 - val_acc: 0.6382\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0901 - acc: 0.6322 - val_loss: 0.0910 - val_acc: 0.6379\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0898 - acc: 0.6329 - val_loss: 0.0908 - val_acc: 0.6407\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0897 - acc: 0.6341 - val_loss: 0.0904 - val_acc: 0.6385\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0896 - acc: 0.6348 - val_loss: 0.0910 - val_acc: 0.6246\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0895 - acc: 0.6347 - val_loss: 0.0919 - val_acc: 0.6359\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0894 - acc: 0.6344 - val_loss: 0.0900 - val_acc: 0.6400\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0892 - acc: 0.6359 - val_loss: 0.0908 - val_acc: 0.6394\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0893 - acc: 0.6354 - val_loss: 0.0899 - val_acc: 0.6358\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0891 - acc: 0.6351 - val_loss: 0.0904 - val_acc: 0.6403\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0889 - acc: 0.6363 - val_loss: 0.0899 - val_acc: 0.6359\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0889 - acc: 0.6353 - val_loss: 0.0900 - val_acc: 0.6369\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0888 - acc: 0.6356 - val_loss: 0.0901 - val_acc: 0.6355\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0890 - acc: 0.6354 - val_loss: 0.0901 - val_acc: 0.6361\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0887 - acc: 0.6357 - val_loss: 0.0897 - val_acc: 0.6393\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0886 - acc: 0.6367 - val_loss: 0.0896 - val_acc: 0.6450\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0886 - acc: 0.6360 - val_loss: 0.0897 - val_acc: 0.6370\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0886 - acc: 0.6365 - val_loss: 0.0898 - val_acc: 0.6426\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0885 - acc: 0.6360 - val_loss: 0.0898 - val_acc: 0.6385\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0885 - acc: 0.6366 - val_loss: 0.0896 - val_acc: 0.6399\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0886 - acc: 0.6362 - val_loss: 0.0895 - val_acc: 0.6378\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0882 - acc: 0.6374 - val_loss: 0.0894 - val_acc: 0.6403\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0883 - acc: 0.6360 - val_loss: 0.0892 - val_acc: 0.6390\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0883 - acc: 0.6362 - val_loss: 0.0895 - val_acc: 0.6360\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0881 - acc: 0.6362 - val_loss: 0.0893 - val_acc: 0.6371\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0881 - acc: 0.6373 - val_loss: 0.0893 - val_acc: 0.6402\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0880 - acc: 0.6362 - val_loss: 0.0895 - val_acc: 0.6351\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0880 - acc: 0.6362 - val_loss: 0.0892 - val_acc: 0.6391\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0880 - acc: 0.6364 - val_loss: 0.0889 - val_acc: 0.6391\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0879 - acc: 0.6375 - val_loss: 0.0887 - val_acc: 0.6404\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0879 - acc: 0.6363 - val_loss: 0.0890 - val_acc: 0.6362\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0879 - acc: 0.6357 - val_loss: 0.0893 - val_acc: 0.6345\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0878 - acc: 0.6365 - val_loss: 0.0889 - val_acc: 0.6404\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0878 - acc: 0.6376 - val_loss: 0.0903 - val_acc: 0.6392\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0879 - acc: 0.6370 - val_loss: 0.0887 - val_acc: 0.6424\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0877 - acc: 0.6366 - val_loss: 0.0888 - val_acc: 0.6342\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0877 - acc: 0.6362 - val_loss: 0.0887 - val_acc: 0.6391\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0876 - acc: 0.6367 - val_loss: 0.0885 - val_acc: 0.6422\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0876 - acc: 0.6375 - val_loss: 0.0888 - val_acc: 0.6416\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0875 - acc: 0.6379 - val_loss: 0.0885 - val_acc: 0.6441\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0876 - acc: 0.6373 - val_loss: 0.0889 - val_acc: 0.6385\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0875 - acc: 0.6375 - val_loss: 0.0884 - val_acc: 0.6397\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0874 - acc: 0.6371 - val_loss: 0.0886 - val_acc: 0.6395\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0874 - acc: 0.6371 - val_loss: 0.0887 - val_acc: 0.6387\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0875 - acc: 0.6374 - val_loss: 0.0885 - val_acc: 0.6389\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0874 - acc: 0.6381 - val_loss: 0.0882 - val_acc: 0.6422\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0873 - acc: 0.6388 - val_loss: 0.0887 - val_acc: 0.6424\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0873 - acc: 0.6388 - val_loss: 0.0884 - val_acc: 0.6467\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0873 - acc: 0.6394 - val_loss: 0.0883 - val_acc: 0.6423\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0872 - acc: 0.6392 - val_loss: 0.0883 - val_acc: 0.6428\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0872 - acc: 0.6388 - val_loss: 0.0885 - val_acc: 0.6401\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0872 - acc: 0.6403 - val_loss: 0.0884 - val_acc: 0.6455\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0872 - acc: 0.6402 - val_loss: 0.0882 - val_acc: 0.6422\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0872 - acc: 0.6396 - val_loss: 0.0880 - val_acc: 0.6454\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0871 - acc: 0.6401 - val_loss: 0.0885 - val_acc: 0.6463\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0871 - acc: 0.6398 - val_loss: 0.0881 - val_acc: 0.6426\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0871 - acc: 0.6404 - val_loss: 0.0880 - val_acc: 0.6429\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0870 - acc: 0.6412 - val_loss: 0.0882 - val_acc: 0.6468\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0871 - acc: 0.6404 - val_loss: 0.0884 - val_acc: 0.6445\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0870 - acc: 0.6401 - val_loss: 0.0879 - val_acc: 0.6464\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0869 - acc: 0.6411 - val_loss: 0.0877 - val_acc: 0.6462\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0870 - acc: 0.6410 - val_loss: 0.0886 - val_acc: 0.6392\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 0.0869 - acc: 0.6415 - val_loss: 0.0880 - val_acc: 0.6397\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0870 - acc: 0.6408 - val_loss: 0.0877 - val_acc: 0.6490\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0868 - acc: 0.6418 - val_loss: 0.0880 - val_acc: 0.6456\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0869 - acc: 0.6413 - val_loss: 0.0879 - val_acc: 0.6394\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0868 - acc: 0.6413 - val_loss: 0.0879 - val_acc: 0.6495\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 0.0869 - acc: 0.6410 - val_loss: 0.0877 - val_acc: 0.6460\n"
     ]
    }
   ],
   "source": [
    "history = flow_autoencoder.fit(\n",
    "    X_train_flow, X_train_flow,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=cb,\n",
    "    validation_data=(X_valid_flow, X_valid_flow)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51ef04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - 1s 529us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.133, 0.375, 0.318, ..., 0.905, 1.455, 1.178])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions = flow_autoencoder.predict(X_test_flow)\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "flow_mse = np.mean(np.power(X_test_flow - reconstructions, 2), axis=1)\n",
    "flow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e35e2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOW POWDER | RECONSTRUCTION LOSS\n",
      "HCS_TaH_-230+PAN | 0.123\n",
      "MW_FeMnAl-C_0-45 | 0.055\n",
      "MW_SS-17-4_10-45 | 0.048\n",
      "V_Al-P1015_99.8%-Al | 0.123\n",
      "WIP-BC1 | 0.089\n"
     ]
    }
   ],
   "source": [
    "test_RE_flow = pd.concat([test_powder_flow, pd.Series(flow_mse, index=test_powder_flow.index, name=\"Reconstruction Error\")], axis = 1)\n",
    "print(\"FLOW POWDER | RECONSTRUCTION LOSS\")\n",
    "for powder, group in test_RE_flow.groupby('Powder'):\n",
    "   print(f\"{powder[:-4]} | {np.mean(group['Reconstruction Error']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0385fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 525us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.495, 3.681, 4.262, ..., 0.038, 0.529, 0.099])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noflow_reconstructions = flow_autoencoder.predict(X_test_noflow)\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "noflow_mse = np.mean(np.power(X_test_noflow - noflow_reconstructions, 2), axis=1)\n",
    "noflow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d308abc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOFLOW POWDER | RECONSTRUCTION LOSS\n",
      "HCS_C103N1_+10,-45 | 0.309\n",
      "HCS_C103N2_+10,-45 | 0.227\n",
      "S1VRC0706-6_Excel | 0.362\n",
      "Valimet_6061_SPE | 0.805\n"
     ]
    }
   ],
   "source": [
    "test_RE_noflow = pd.concat([test_powder_noflow, pd.Series(noflow_mse, index=test_powder_noflow.index, name=\"Reconstruction Error\")], axis = 1)\n",
    "print(\"NOFLOW POWDER | RECONSTRUCTION LOSS\")\n",
    "for powder, group in test_RE_noflow.groupby('Powder'):\n",
    "    print(f\"{powder[:-4]} | {np.mean(group['Reconstruction Error']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d974d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3015/3015 [==============================] - 2s 504us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.514, 0.046, 1.124, ..., 1.799, 1.966, 1.882])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noflow_reconstructions = flow_autoencoder.predict(flow_scaler.transform(train_df_noflow))\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "noflow_mse = np.mean(np.power(flow_scaler.transform(train_df_noflow) - noflow_reconstructions, 2), axis=1)\n",
    "noflow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af03e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOFLOW POWDER | RECONSTRUCTION LOSS\n",
      "AEE_WP-301_1-5_AA_3-7 | 0.380\n",
      "HCS_C103H_+10,-45 | 0.071\n",
      "MW_I_718_0-10 | 0.085\n",
      "S1VRC0706-4_Excel | 0.116\n",
      "S1VRC0706-5_Excel | 0.104\n"
     ]
    }
   ],
   "source": [
    "train_RE_noflow = pd.concat([train_powder_noflow, pd.Series(noflow_mse, index=train_powder_noflow.index, name=\"Reconstruction Error\")], axis = 1)\n",
    "print(\"NOFLOW POWDER | RECONSTRUCTION LOSS\")\n",
    "for powder, group in train_RE_noflow.groupby('Powder'):\n",
    "    print(f\"{powder[:-4]} | {np.mean(group['Reconstruction Error']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdcdbd7",
   "metadata": {},
   "source": [
    "# Second Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9cdeb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "def load_data():\n",
    "    x = Data()\n",
    "    x.importnewpowders()\n",
    "    df_data = pd.DataFrame(x.data)\n",
    "    df_flow = pd.DataFrame(x.flow)\n",
    "    df_noflow = pd.DataFrame(x.noflow)\n",
    "\n",
    "    return df_data, df_flow, df_noflow\n",
    "\n",
    "df_data, df_flow, df_noflow = load_data()\n",
    "\n",
    "df_all = df_data.copy()\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71bd530b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MW_Ti-Nb_64-150.txt', 'MW_Ti-Nb_0-63.txt', 'HCS_TaH_-230+PAN.txt',\n",
       "       'MW_SS-17-4_10-45.txt', 'Lincoln_SHS_9172HV.txt',\n",
       "       'MW_SS-17-4_64-150.txt', 'Lincoln_SHS_7574HV.txt',\n",
       "       'Lincoln_SHS_8000HV.txt', 'WIP-BC1.txt', 'S1VRC0706-3_Excel.txt',\n",
       "       'WIP-C1.txt', 'S1VRC0706-1_Excel.txt', 'WIP-W1.txt',\n",
       "       'MW_Ti-Nb-Zr_64-150.txt', 'S1VRC0706-2_Excel.txt',\n",
       "       'MW_Ti-Nb-Zr_0-63.txt', 'WIP-W2.txt'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow[[\"Powder\", \"Flow\"]].drop_duplicates().sort_values(\"Flow\")[:-7].Powder.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12fa94c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['V6_Al-P1015_99.8%-Al.txt', 'V_Al-P1015_99.8%-Al.txt',\n",
       "       'V_AA-4047.txt', 'V5_Al-P1015_99.8%-Al.txt', 'V_AA-2024.txt',\n",
       "       'MW_FeMnAl-C_0-45.txt', 'Al-Cr_75-Percent_6061_1.1.txt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow[[\"Powder\", \"Flow\"]].drop_duplicates().sort_values(\"Flow\")[-7:].Powder.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f3bb094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_flow = df_flow.copy().reset_index(drop = True)\n",
    "\n",
    "good_flow_powders = ['MW_Ti-Nb_64-150.txt', 'MW_Ti-Nb_0-63.txt', 'HCS_TaH_-230+PAN.txt',\n",
    "       'MW_SS-17-4_10-45.txt', 'Lincoln_SHS_9172HV.txt',\n",
    "       'MW_SS-17-4_64-150.txt', 'Lincoln_SHS_7574HV.txt',\n",
    "       'Lincoln_SHS_8000HV.txt', 'WIP-BC1.txt', 'S1VRC0706-3_Excel.txt',\n",
    "       'WIP-C1.txt', 'S1VRC0706-1_Excel.txt', 'WIP-W1.txt',\n",
    "       'MW_Ti-Nb-Zr_64-150.txt', 'S1VRC0706-2_Excel.txt',\n",
    "       'MW_Ti-Nb-Zr_0-63.txt', 'WIP-W2.txt']\n",
    "bad_flow_powders = ['V6_Al-P1015_99.8%-Al.txt', 'V_Al-P1015_99.8%-Al.txt',\n",
    "       'V_AA-4047.txt', 'V5_Al-P1015_99.8%-Al.txt', 'V_AA-2024.txt',\n",
    "       'MW_FeMnAl-C_0-45.txt', 'Al-Cr_75-Percent_6061_1.1.txt']\n",
    "\n",
    "train_flow_powders, test_flow_powders = train_test_split(good_flow_powders, test_size=0.5)\n",
    "\n",
    "df_badflow = df_flow[df_flow[\"Powder\"].isin(bad_flow_powders)]\n",
    "df_flow = df_flow.drop(df_flow[df_flow[\"Powder\"].isin(bad_flow_powders)].index)\n",
    "\n",
    "train_df_flow = df_flow.drop(df_flow[df_flow['Powder'].isin(test_flow_powders)].index)\n",
    "test_df_flow = df_flow.drop(df_flow[df_flow['Powder'].isin(train_flow_powders)].index)\n",
    "\n",
    "train_powder_flow = train_df_flow.pop(\"Powder\")\n",
    "train_flow = train_df_flow.pop(\"Flow\")\n",
    "train_target_flow = train_df_flow.pop(\"Flow Class\")\n",
    "\n",
    "test_powder_flow = test_df_flow.pop(\"Powder\")\n",
    "test_flow = test_df_flow.pop(\"Flow\")\n",
    "test_target_flow = test_df_flow.pop(\"Flow Class\")\n",
    "\n",
    "bad_powder_flow = df_badflow.pop(\"Powder\")\n",
    "bad_flow = df_badflow.pop(\"Flow\")\n",
    "bad_target_flow = df_badflow.pop(\"Flow Class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16d7e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "flow_scaler = StandardScaler()\n",
    "\n",
    "X_valid_flow = train_df_flow.sample(int(len(train_df_flow) * 0.2))\n",
    "X_train_flow = train_df_flow.drop(X_valid_flow.index)\n",
    "\n",
    "X_train_flow = flow_scaler.fit_transform(X_train_flow)\n",
    "X_valid_flow = flow_scaler.transform(X_valid_flow)\n",
    "X_test_flow = flow_scaler.transform(test_df_flow)\n",
    "\n",
    "X_bad_flow = flow_scaler.transform(df_badflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19b37476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noflow = df_noflow.reset_index(drop = True)\n",
    "\n",
    "train_noflow_powders = ['MW_I_718_0-10.txt', 'S1VRC0706-5_Excel.txt',\n",
    "       'HCS_C103H_+10,-45.txt', 'S1VRC0706-4_Excel.txt',\n",
    "       'AEE_WP-301_1-5_AA_3-7.txt']\n",
    "test_noflow_powders = ['HCS_C103N2_+10,-45.txt',\n",
    "       'HCS_C103N1_+10,-45.txt', 'S1VRC0706-6_Excel.txt',\n",
    "       'Valimet_6061_SPE.txt']\n",
    "\n",
    "train_df_noflow = df_noflow.drop(df_noflow[df_noflow['Powder'].isin(test_noflow_powders)].index)\n",
    "test_df_noflow = df_noflow.drop(df_noflow[df_noflow['Powder'].isin(train_noflow_powders)].index)\n",
    "\n",
    "train_powder_noflow = train_df_noflow.pop(\"Powder\")\n",
    "train_df_noflow.pop(\"Flow\")\n",
    "train_target_noflow = train_df_noflow.pop(\"Flow Class\")\n",
    "\n",
    "test_powder_noflow = test_df_noflow.pop(\"Powder\")\n",
    "test_df_noflow.pop(\"Flow\")\n",
    "test_target_noflow = test_df_noflow.pop(\"Flow Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ebd4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "noflow_scaler = StandardScaler()\n",
    "\n",
    "# X_valid_noflow = train_df_noflow.sample(int(len(train_df_noflow) * 0.2))\n",
    "# X_train_noflow = train_df_noflow.drop(X_valid_noflow.index)\n",
    "\n",
    "X_train_noflow = noflow_scaler.fit_transform(train_df_noflow)\n",
    "#X_train_noflow = noflow_scaler.fit_transform(X_train_noflow)\n",
    "# X_valid_noflow = noflow_scaler.transform(X_valid_noflow)\n",
    "X_test_noflow = noflow_scaler.transform(test_df_noflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5ec7c",
   "metadata": {},
   "source": [
    "## GoodFlow AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "753d7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dimensions // hyperparameters \n",
    "input_dim = X_train_flow.shape[1]\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "\n",
    "# https://keras.io/layers/core/\n",
    "goodflow_autoencoder = tf.keras.models.Sequential([\n",
    "    \n",
    "    # deconstruct / encode\n",
    "    tf.keras.layers.Dense(input_dim, activation='elu', input_shape=(input_dim, )), \n",
    "    tf.keras.layers.Dense(16, activation='elu'),\n",
    "    tf.keras.layers.Dense(8, activation='elu'),\n",
    "    tf.keras.layers.Dense(4, activation='elu'),\n",
    "    tf.keras.layers.Dense(3, activation='elu'),\n",
    "    \n",
    "    # reconstruction / decode\n",
    "    tf.keras.layers.Dense(4, activation='elu'),\n",
    "    tf.keras.layers.Dense(8, activation='elu'),\n",
    "    tf.keras.layers.Dense(16, activation='elu'),\n",
    "    tf.keras.layers.Dense(input_dim, activation='elu')\n",
    "    \n",
    "])\n",
    "\n",
    "# https://keras.io/api/models/model_training_apis/\n",
    "goodflow_autoencoder.compile(optimizer=\"adam\", \n",
    "                    loss=\"mse\",\n",
    "                    metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a9b4273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "yyyymmddHHMM = datetime.now().strftime('%Y%m%d%H%M')\n",
    "\n",
    "# new folder for a new run\n",
    "log_subdir = f'{yyyymmddHHMM}_batch{BATCH_SIZE}_layers{len(goodflow_autoencoder.layers)}'\n",
    "\n",
    "# define our early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=10,\n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='autoencoder_best_weights.hdf5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    f'logs/{log_subdir}',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    update_freq='batch'\n",
    ")\n",
    "\n",
    "# callbacks argument only takes a list\n",
    "cb = [early_stop, save_model, tensorboard]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13b4338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.5143 - acc: 0.2230 - val_loss: 0.2596 - val_acc: 0.3206\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.2259 - acc: 0.3178 - val_loss: 0.2011 - val_acc: 0.3164\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1942 - acc: 0.3527 - val_loss: 0.1860 - val_acc: 0.3781\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1836 - acc: 0.3820 - val_loss: 0.1772 - val_acc: 0.3919\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1633 - acc: 0.4210 - val_loss: 0.1293 - val_acc: 0.4961\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1151 - acc: 0.5509 - val_loss: 0.1067 - val_acc: 0.5740\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1072 - acc: 0.5803 - val_loss: 0.1036 - val_acc: 0.5927\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1047 - acc: 0.5911 - val_loss: 0.1019 - val_acc: 0.5938\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1032 - acc: 0.5965 - val_loss: 0.1005 - val_acc: 0.5970\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1020 - acc: 0.5992 - val_loss: 0.0992 - val_acc: 0.6014\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.1008 - acc: 0.5995 - val_loss: 0.0982 - val_acc: 0.5994\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0996 - acc: 0.5998 - val_loss: 0.0969 - val_acc: 0.6005\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0987 - acc: 0.5978 - val_loss: 0.0969 - val_acc: 0.6012\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0976 - acc: 0.5953 - val_loss: 0.0951 - val_acc: 0.5967\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0968 - acc: 0.5932 - val_loss: 0.0947 - val_acc: 0.5661\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0962 - acc: 0.5919 - val_loss: 0.0939 - val_acc: 0.5895\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0956 - acc: 0.5926 - val_loss: 0.0933 - val_acc: 0.5973\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0951 - acc: 0.5900 - val_loss: 0.0928 - val_acc: 0.5901\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0945 - acc: 0.5917 - val_loss: 0.0921 - val_acc: 0.5904\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0942 - acc: 0.5910 - val_loss: 0.0922 - val_acc: 0.5959\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0934 - acc: 0.5921 - val_loss: 0.0914 - val_acc: 0.5961\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0928 - acc: 0.5952 - val_loss: 0.0907 - val_acc: 0.5986\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0924 - acc: 0.5988 - val_loss: 0.0905 - val_acc: 0.5973\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0918 - acc: 0.6025 - val_loss: 0.0900 - val_acc: 0.6082\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0914 - acc: 0.6046 - val_loss: 0.0895 - val_acc: 0.6161\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0910 - acc: 0.6070 - val_loss: 0.0890 - val_acc: 0.6062\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0906 - acc: 0.6076 - val_loss: 0.0889 - val_acc: 0.6191\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0906 - acc: 0.6085 - val_loss: 0.0900 - val_acc: 0.6122\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0902 - acc: 0.6081 - val_loss: 0.0884 - val_acc: 0.6106\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0900 - acc: 0.6095 - val_loss: 0.0886 - val_acc: 0.6163\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0898 - acc: 0.6138 - val_loss: 0.0893 - val_acc: 0.6080\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0896 - acc: 0.6144 - val_loss: 0.0878 - val_acc: 0.6150\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0895 - acc: 0.6166 - val_loss: 0.0880 - val_acc: 0.6204\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0893 - acc: 0.6176 - val_loss: 0.0878 - val_acc: 0.6205\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0893 - acc: 0.6163 - val_loss: 0.0877 - val_acc: 0.6194\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0890 - acc: 0.6168 - val_loss: 0.0873 - val_acc: 0.6202\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0889 - acc: 0.6184 - val_loss: 0.0871 - val_acc: 0.6248\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0887 - acc: 0.6210 - val_loss: 0.0871 - val_acc: 0.6214\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0885 - acc: 0.6205 - val_loss: 0.0869 - val_acc: 0.6250\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0884 - acc: 0.6204 - val_loss: 0.0868 - val_acc: 0.6240\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0883 - acc: 0.6199 - val_loss: 0.0873 - val_acc: 0.6117\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0882 - acc: 0.6236 - val_loss: 0.0863 - val_acc: 0.6277\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0880 - acc: 0.6227 - val_loss: 0.0864 - val_acc: 0.6277\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0878 - acc: 0.6238 - val_loss: 0.0867 - val_acc: 0.6006\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0878 - acc: 0.6250 - val_loss: 0.0862 - val_acc: 0.6260\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0877 - acc: 0.6263 - val_loss: 0.0860 - val_acc: 0.6196\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0877 - acc: 0.6234 - val_loss: 0.0860 - val_acc: 0.6248\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0876 - acc: 0.6280 - val_loss: 0.0862 - val_acc: 0.6067\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0877 - acc: 0.6236 - val_loss: 0.0859 - val_acc: 0.6164\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0876 - acc: 0.6289 - val_loss: 0.0859 - val_acc: 0.6238\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0874 - acc: 0.6254 - val_loss: 0.0857 - val_acc: 0.6353\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0873 - acc: 0.6280 - val_loss: 0.0857 - val_acc: 0.6341\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0873 - acc: 0.6277 - val_loss: 0.0859 - val_acc: 0.6084\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0872 - acc: 0.6261 - val_loss: 0.0855 - val_acc: 0.6121\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0872 - acc: 0.6274 - val_loss: 0.0859 - val_acc: 0.6120\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0871 - acc: 0.6276 - val_loss: 0.0857 - val_acc: 0.6359\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0871 - acc: 0.6300 - val_loss: 0.0855 - val_acc: 0.6142\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0870 - acc: 0.6268 - val_loss: 0.0853 - val_acc: 0.6272\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0869 - acc: 0.6294 - val_loss: 0.0851 - val_acc: 0.6323\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0869 - acc: 0.6314 - val_loss: 0.0852 - val_acc: 0.6155\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0868 - acc: 0.6273 - val_loss: 0.0849 - val_acc: 0.6287\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0869 - acc: 0.6280 - val_loss: 0.0854 - val_acc: 0.6304\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0868 - acc: 0.6278 - val_loss: 0.0850 - val_acc: 0.6267\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0867 - acc: 0.6288 - val_loss: 0.0854 - val_acc: 0.6284\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0867 - acc: 0.6262 - val_loss: 0.0852 - val_acc: 0.6296\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0866 - acc: 0.6289 - val_loss: 0.0847 - val_acc: 0.6277\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0865 - acc: 0.6288 - val_loss: 0.0853 - val_acc: 0.6244\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0866 - acc: 0.6274 - val_loss: 0.0848 - val_acc: 0.6277\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0865 - acc: 0.6270 - val_loss: 0.0857 - val_acc: 0.5971\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0864 - acc: 0.6281 - val_loss: 0.0854 - val_acc: 0.6290\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0864 - acc: 0.6276 - val_loss: 0.0847 - val_acc: 0.6358\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0862 - acc: 0.6304 - val_loss: 0.0842 - val_acc: 0.6322\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0863 - acc: 0.6276 - val_loss: 0.0841 - val_acc: 0.6299\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0861 - acc: 0.6301 - val_loss: 0.0842 - val_acc: 0.6201\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0862 - acc: 0.6289 - val_loss: 0.0847 - val_acc: 0.6294\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0862 - acc: 0.6273 - val_loss: 0.0841 - val_acc: 0.6335\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0860 - acc: 0.6277 - val_loss: 0.0841 - val_acc: 0.6185\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0860 - acc: 0.6292 - val_loss: 0.0841 - val_acc: 0.6187\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0860 - acc: 0.6277 - val_loss: 0.0839 - val_acc: 0.6110\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0859 - acc: 0.6281 - val_loss: 0.0839 - val_acc: 0.6176\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0860 - acc: 0.6257 - val_loss: 0.0840 - val_acc: 0.6163\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.6294 - val_loss: 0.0841 - val_acc: 0.6074\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0858 - acc: 0.6295 - val_loss: 0.0848 - val_acc: 0.6247\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0858 - acc: 0.6290 - val_loss: 0.0841 - val_acc: 0.6203\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.6300 - val_loss: 0.0839 - val_acc: 0.6236\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0856 - acc: 0.6299 - val_loss: 0.0838 - val_acc: 0.6273\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0855 - acc: 0.6299 - val_loss: 0.0839 - val_acc: 0.6343\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.6284 - val_loss: 0.0836 - val_acc: 0.6298\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0854 - acc: 0.6278 - val_loss: 0.0839 - val_acc: 0.6301\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0856 - acc: 0.6298 - val_loss: 0.0836 - val_acc: 0.6280\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0854 - acc: 0.6298 - val_loss: 0.0838 - val_acc: 0.6294\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0853 - acc: 0.6291 - val_loss: 0.0834 - val_acc: 0.6303\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.6298 - val_loss: 0.0841 - val_acc: 0.6290\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0853 - acc: 0.6298 - val_loss: 0.0834 - val_acc: 0.6244\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0853 - acc: 0.6303 - val_loss: 0.0834 - val_acc: 0.6364\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0853 - acc: 0.6303 - val_loss: 0.0834 - val_acc: 0.6309\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.6314 - val_loss: 0.0835 - val_acc: 0.6314\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0851 - acc: 0.6302 - val_loss: 0.0833 - val_acc: 0.6238\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0851 - acc: 0.6294 - val_loss: 0.0832 - val_acc: 0.6295\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0851 - acc: 0.6303 - val_loss: 0.0836 - val_acc: 0.6253\n"
     ]
    }
   ],
   "source": [
    "history = goodflow_autoencoder.fit(\n",
    "    X_train_flow, X_train_flow,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=cb,\n",
    "    validation_data=(X_valid_flow, X_valid_flow)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70814f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565/1565 [==============================] - 1s 533us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.037, 0.004, 0.05 , ..., 0.01 , 0.012, 0.014])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions = goodflow_autoencoder.predict(X_train_flow)\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "flow_mse = np.mean(np.power(X_train_flow - reconstructions, 2), axis=1)\n",
    "flow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4aa055d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1706/1706 [==============================] - 1s 553us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.304, 0.075, 3.131, ..., 0.038, 0.005, 0.05 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions = goodflow_autoencoder.predict(X_test_flow)\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "flow_mse = np.mean(np.power(X_test_flow - reconstructions, 2), axis=1)\n",
    "flow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d706e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOW POWDER | RECONSTRUCTION LOSS\n",
      "HCS_TaH_-230+PAN | 0.148\n",
      "Lincoln_SHS_7574HV | 0.134\n",
      "MW_SS-17-4_10-45 | 0.052\n",
      "MW_Ti-Nb-Zr_0-63 | 0.069\n",
      "MW_Ti-Nb-Zr_64-150 | 0.344\n",
      "MW_Ti-Nb_0-63 | 0.067\n",
      "S1VRC0706-1_Excel | 0.120\n",
      "S1VRC0706-2_Excel | 0.598\n",
      "WIP-W1 | 0.162\n"
     ]
    }
   ],
   "source": [
    "test_RE_flow = pd.concat([test_powder_flow, pd.Series(flow_mse, index=test_powder_flow.index, name=\"Reconstruction Error\")], axis = 1)\n",
    "print(\"FLOW POWDER | RECONSTRUCTION LOSS\")\n",
    "for powder, group in test_RE_flow.groupby('Powder'):\n",
    "   print(f\"{powder[:-4]} | {np.mean(group['Reconstruction Error']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c06ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Powder</th>\n",
       "      <th>Flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72074</th>\n",
       "      <td>MW_Ti-Nb_64-150.txt</td>\n",
       "      <td>2.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108235</th>\n",
       "      <td>MW_Ti-Nb_0-63.txt</td>\n",
       "      <td>2.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125748</th>\n",
       "      <td>HCS_TaH_-230+PAN.txt</td>\n",
       "      <td>4.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96526</th>\n",
       "      <td>MW_SS-17-4_10-45.txt</td>\n",
       "      <td>14.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81795</th>\n",
       "      <td>Lincoln_SHS_9172HV.txt</td>\n",
       "      <td>15.326667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72914</th>\n",
       "      <td>MW_SS-17-4_64-150.txt</td>\n",
       "      <td>16.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73731</th>\n",
       "      <td>Lincoln_SHS_7574HV.txt</td>\n",
       "      <td>16.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117595</th>\n",
       "      <td>Lincoln_SHS_8000HV.txt</td>\n",
       "      <td>16.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124225</th>\n",
       "      <td>WIP-BC1.txt</td>\n",
       "      <td>19.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1VRC0706-3_Excel.txt</td>\n",
       "      <td>20.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>WIP-C1.txt</td>\n",
       "      <td>21.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116533</th>\n",
       "      <td>S1VRC0706-1_Excel.txt</td>\n",
       "      <td>22.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14007</th>\n",
       "      <td>WIP-W1.txt</td>\n",
       "      <td>25.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71185</th>\n",
       "      <td>MW_Ti-Nb-Zr_64-150.txt</td>\n",
       "      <td>26.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72758</th>\n",
       "      <td>S1VRC0706-2_Excel.txt</td>\n",
       "      <td>30.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28884</th>\n",
       "      <td>MW_Ti-Nb-Zr_0-63.txt</td>\n",
       "      <td>33.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37346</th>\n",
       "      <td>WIP-W2.txt</td>\n",
       "      <td>34.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Powder       Flow\n",
       "72074      MW_Ti-Nb_64-150.txt   2.380000\n",
       "108235       MW_Ti-Nb_0-63.txt   2.550000\n",
       "125748    HCS_TaH_-230+PAN.txt   4.545500\n",
       "96526     MW_SS-17-4_10-45.txt  14.430000\n",
       "81795   Lincoln_SHS_9172HV.txt  15.326667\n",
       "72914    MW_SS-17-4_64-150.txt  16.030000\n",
       "73731   Lincoln_SHS_7574HV.txt  16.260000\n",
       "117595  Lincoln_SHS_8000HV.txt  16.866667\n",
       "124225             WIP-BC1.txt  19.430000\n",
       "0        S1VRC0706-3_Excel.txt  20.013333\n",
       "803                 WIP-C1.txt  21.786667\n",
       "116533   S1VRC0706-1_Excel.txt  22.490000\n",
       "14007               WIP-W1.txt  25.786667\n",
       "71185   MW_Ti-Nb-Zr_64-150.txt  26.100000\n",
       "72758    S1VRC0706-2_Excel.txt  30.153333\n",
       "28884     MW_Ti-Nb-Zr_0-63.txt  33.970000\n",
       "37346               WIP-W2.txt  34.310000"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow[[\"Powder\", \"Flow\"]].drop_duplicates().sort_values(\"Flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d632760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072/1072 [==============================] - 1s 519us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.438, 0.067, 0.213, ..., 0.967, 1.569, 1.261])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions = goodflow_autoencoder.predict(X_bad_flow)\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "badflow_mse = np.mean(np.power(X_bad_flow - reconstructions, 2), axis=1)\n",
    "badflow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e697a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD FLOW POWDER | RECONSTRUCTION LOSS\n",
      "Al-Cr_75-Percent_6061_1.1 | 0.089\n",
      "MW_FeMnAl-C_0-45 | 0.060\n",
      "V5_Al-P1015_99.8%-Al | 0.132\n",
      "V6_Al-P1015_99.8%-Al | 0.102\n",
      "V_AA-2024 | 0.071\n",
      "V_AA-4047 | 0.194\n",
      "V_Al-P1015_99.8%-Al | 0.137\n"
     ]
    }
   ],
   "source": [
    "bad_RE_flow = pd.concat([bad_powder_flow, pd.Series(badflow_mse, index=bad_powder_flow.index, name=\"Reconstruction Error\")], axis = 1)\n",
    "print(\"BAD FLOW POWDER | RECONSTRUCTION LOSS\")\n",
    "for powder, group in bad_RE_flow.groupby('Powder'):\n",
    "   print(f\"{powder[:-4]} | {np.mean(group['Reconstruction Error']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f927723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 508us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.114, 3.128, 3.129, ..., 0.057, 0.515, 0.085])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noflow_reconstructions = goodflow_autoencoder.predict(X_test_noflow)\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "noflow_mse = np.mean(np.power(X_test_noflow - noflow_reconstructions, 2), axis=1)\n",
    "noflow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6d9336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOFLOW POWDER | RECONSTRUCTION LOSS\n",
      "HCS_C103N1_+10,-45 | 0.290\n",
      "HCS_C103N2_+10,-45 | 0.214\n",
      "S1VRC0706-6_Excel | 0.341\n",
      "Valimet_6061_SPE | 0.774\n"
     ]
    }
   ],
   "source": [
    "test_RE_noflow = pd.concat([test_powder_noflow, pd.Series(noflow_mse, index=test_powder_noflow.index, name=\"Reconstruction Error\")], axis = 1)\n",
    "print(\"NOFLOW POWDER | RECONSTRUCTION LOSS\")\n",
    "for powder, group in test_RE_noflow.groupby('Powder'):\n",
    "    print(f\"{powder[:-4]} | {np.mean(group['Reconstruction Error']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a56f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3015/3015 [==============================] - 2s 525us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.198, 0.682, 2.152, ..., 1.178, 1.266, 1.203])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noflow_reconstructions = goodflow_autoencoder.predict(X_train_noflow)\n",
    "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
    "noflow_mse = np.mean(np.power(X_train_noflow - noflow_reconstructions, 2), axis=1)\n",
    "noflow_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "452f684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOFLOW POWDER | RECONSTRUCTION LOSS\n",
      "AEE_WP-301_1-5_AA_3-7 | 0.481\n",
      "HCS_C103H_+10,-45 | 0.429\n",
      "MW_I_718_0-10 | 0.091\n",
      "S1VRC0706-4_Excel | 0.640\n",
      "S1VRC0706-5_Excel | 0.626\n"
     ]
    }
   ],
   "source": [
    "train_RE_noflow = pd.concat([train_powder_noflow, pd.Series(noflow_mse, index=train_powder_noflow.index, name=\"Reconstruction Error\")], axis = 1)\n",
    "print(\"NOFLOW POWDER | RECONSTRUCTION LOSS\")\n",
    "for powder, group in train_RE_noflow.groupby('Powder'):\n",
    "    print(f\"{powder[:-4]} | {np.mean(group['Reconstruction Error']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a4d9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = pd.concat([test_RE_flow, bad_RE_flow, train_RE_noflow, test_RE_noflow], keys=['test_RE_flow', 'bad_RE_flow', 'train_RE_noflow', 'test_RE_noflow'], axis = 0)\n",
    "RE_g = RE.groupby(['Powder']).agg(\"mean\")\n",
    "# ax = RE_g.unstack(level=0).plot(kind='bar', subplots=True, rot=0, figsize=(9, 7), layout=(2, 3))\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9774a4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 25 artists>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = RE.copy()\n",
    "a = a.reset_index()\n",
    "a.pop('level_1')\n",
    "grouped_df =  a.groupby(['level_0', 'Powder']).mean()\n",
    "level_0 = grouped_df.index.get_level_values(0)\n",
    "means = grouped_df.values\n",
    "plt.bar(level_0,  np.squeeze(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2cdfa4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "ax = grouped_df.plot.bar()\n",
    "ax.set_xticklabels(\"\")\n",
    "ax.set_xlabel(\"Test Powder\")\n",
    "ax2 =  ax.twiny()\n",
    "offset = 0, -5\n",
    "\n",
    "ax2.set_xticks([0.0, 0.64, 1.0])\n",
    "ax2.axvline(0.64)\n",
    "ax2.axhline(0.2)\n",
    "ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax2.xaxis.set_minor_locator(ticker.FixedLocator([0.3, 0.8]))\n",
    "ax2.xaxis.set_minor_formatter(ticker.FixedFormatter(['Positive Instances', 'Negative Instances']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('VAE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c59c1238fe2c4450f3a4efe2462d39a9bd2040024d9db1348747404bb16a7efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
