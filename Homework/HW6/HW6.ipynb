{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8be85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3634a2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Loading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96d22dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4439739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770b774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d3a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28f1ea2f-0796-437f-bac8-0be319b3caf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_split(dataset, random_seed = 42):\n",
    "    train_split = 0.8\n",
    "    random_seed = 42\n",
    "\n",
    "    dataset_size = len(dataset)\n",
    "    validation_split = .2\n",
    "    \n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    \n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(train_indices)\n",
    "    random.shuffle(val_indices)\n",
    "    \n",
    "    train = [dataset[i] for i in train_indices]\n",
    "    val = [dataset[j] for j in val_indices]\n",
    "    \n",
    "    return train, val\n",
    "\n",
    "#any(word in train for word in val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2dd05b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2803\n",
      "fra 4345\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e89af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8870ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ad5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de08ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460187c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062bda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7527ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cbf81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fe73920",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec118ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f13ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, enc_learning_rate = 0, dec_learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=enc_learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=dec_learning_rate)\n",
    "    \n",
    "    train_, val_ = train_test_split(pairs, random_seed = 42)\n",
    "    \n",
    "    training_pairs = [tensorsFromPair(random.choice(train_))\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25d6ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77364c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "633cdf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "97f3e9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 27s (- 8m 39s) (1000 5%) 4.2078\n",
      "0m 59s (- 8m 54s) (2000 10%) 3.6780\n",
      "1m 27s (- 8m 13s) (3000 15%) 3.4738\n",
      "1m 58s (- 7m 54s) (4000 20%) 3.2387\n",
      "2m 27s (- 7m 22s) (5000 25%) 3.1660\n",
      "2m 58s (- 6m 56s) (6000 30%) 3.0595\n",
      "3m 27s (- 6m 24s) (7000 35%) 2.9013\n",
      "3m 59s (- 5m 59s) (8000 40%) 2.8575\n",
      "4m 29s (- 5m 29s) (9000 45%) 2.7806\n",
      "5m 1s (- 5m 1s) (10000 50%) 2.7396\n",
      "5m 30s (- 4m 30s) (11000 55%) 2.5351\n",
      "6m 0s (- 4m 0s) (12000 60%) 2.4768\n",
      "6m 29s (- 3m 29s) (13000 65%) 2.4918\n",
      "6m 59s (- 2m 59s) (14000 70%) 2.3806\n",
      "7m 28s (- 2m 29s) (15000 75%) 2.3577\n",
      "8m 2s (- 2m 0s) (16000 80%) 2.3057\n",
      "8m 31s (- 1m 30s) (17000 85%) 2.1871\n",
      "9m 1s (- 1m 0s) (18000 90%) 2.1282\n",
      "9m 30s (- 0m 30s) (19000 95%) 2.0965\n",
      "10m 1s (- 0m 0s) (20000 100%) 2.1175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size =EncoderRNN\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "plot_losses = trainIters(encoder1, attn_decoder1, 20000, print_every=1000, plot_every=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
